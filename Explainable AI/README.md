# Explainable AI
## Task Description
* 透過更加透明化的資訊來了解模型判斷的依據和背後原因，以此幫助建模者除錯和改善模型
  * Saliency Map
  * Filter Visualization
  * Lime
  * Confusion Matrix
* 利用在CNN的task中使用的dataset和訓練完的模型並實作各種explainable AI的方法
## Download Dataset
<img src="output/dataset.png" width=700 height=60 /> <br>
## Implementation
### Saliency Map
<img src="output/saliency_1.png" width=960 height=420 /> <br>
<img src="output/saliency_2.png" width=840 height=465 /> <br>
### Filter Visualization
<img src="output/filter.png" width=840 height=1200 /> <br>
### Lime
<img src="output/lime.png" width=1000 height=290 /> <br>
### Confusion Matrix
<img src="output/confusionmatrix.png" width=800 height=600 /> <br>

---
### Reference:
投影片部份取自李宏毅教授的機器學習課程 (
[Explainable AI](http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2019/Lecture/XAI%20(v7).pdf)
[作業說明投影片](https://docs.google.com/presentation/d/1VClvgyilAvohextY0tM3gD7YemXGSUrzLV0E8RjDnMU/edit) )
